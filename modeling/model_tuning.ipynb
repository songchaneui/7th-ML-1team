{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukott0e6bAOs"
      },
      "source": [
        "##데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCkPKv77bg0y",
        "outputId": "1aaa3c69-2817-4c84-dfb1-68b80eee59af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clv9Tg_zbis2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/KHUDA_7th_YB_ToyProject/data/merge_data.csv') #data\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/KHUDA_7th_YB_ToyProject/data/merge_target.csv') #target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X1pd5vZbm8l",
        "outputId": "fe728122-6329-4cf0-e94c-edf19a570bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "3    1378\n",
            "1     490\n",
            "4     456\n",
            "2     302\n",
            "0     280\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "target_counts = df2['0'].value_counts()\n",
        "print(target_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfg0Vvgm8myb"
      },
      "source": [
        "['데이터 분석가' '데이터 사이언티스트' '데이터 엔지니어' '백엔드' '프론트엔드']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpHRYdXcbqJY"
      },
      "source": [
        "#데이터 분할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q92kFW9zbrEa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(df1,df2,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkcbU2A4bttF",
        "outputId": "eaecd16a-13b0-42e4-a7f5-f5638409d719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape is :  (2324, 14483)\n",
            "X_test.shape is :  (582, 14483)\n",
            "y_train.shape is :  (2324, 1)\n",
            "y_test.shape is :  (582, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train.shape is : \",X_train.shape)\n",
        "print(\"X_test.shape is : \",X_test.shape)\n",
        "print(\"y_train.shape is : \",y_train.shape)\n",
        "print(\"y_test.shape is : \",y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuckhB3E7_hL"
      },
      "source": [
        "#기본 코드 돌려보기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5UBmwda9XVE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "y_train = np.ravel(y_train.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kN1VnTd8fAF",
        "outputId": "f51f8454-c107-419f-d092-4cb26f41d613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8161512027491409\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "\n",
        "svm_linear = SVC(kernel ='linear',random_state=42)\n",
        "svm_linear.fit(X_train,y_train)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_pred = svm_linear.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTxOqlJm9NCT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1e6772-386c-4935-c1c6-b9751d4b632b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6872852233676976\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "\n",
        "svm_rbf = SVC(kernel ='rbf',random_state=42)\n",
        "svm_rbf.fit(X_train,y_train)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_pred = svm_rbf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smG0TAjZ9QRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92a592c-2ed5-4c7e-98d9-624c61e3a6ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7096219931271478\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train,y_train)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYFKNhP5cNUl"
      },
      "source": [
        "#SVM Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##그리드 서치"
      ],
      "metadata": {
        "id": "TzBj8oXrL1Uc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2YCmwYzcPFa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "\n",
        "#그리드서치\n",
        "#scoring -> accuracy, f1-score 둘 다 해보기\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # 작은 값은 규제를 강하게, 큰 값은 규제를 약하게\n",
        "  }\n",
        "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적 모델 확인\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
        "print(f\"훈련 데이터 최적 정확도: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# 🔹 6. 평가 결과 출력\n",
        "print(f\"테스트 데이터 평가 결과:\")\n",
        "print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "print(f\"정밀도 (Precision): {precision:.4f}\")\n",
        "print(f\"재현율 (Recall): {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnSlv3X3jgl3",
        "outputId": "3db1ba62-d8ee-442a-e65e-a7eb2ef8bfdc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 최적의 SVM 모델이 'best_svm_model.pkl'로 저장되었습니다!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# 🔹 최적의 C값으로 SVM 모델 생성\n",
        "best_svm = SVC(kernel='linear', C=10)\n",
        "best_svm.fit(X_train, y_train)  # 모델 학습\n",
        "\n",
        "# 🔹 모델 저장 (Pickle 사용)\n",
        "with open(\"best_svm_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_svm, f)\n",
        "\n",
        "print(\"✅ 최적의 SVM 모델이 'best_svm_model.pkl'로 저장되었습니다!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az_2AnxTe2oC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "\n",
        "#그리드서치\n",
        "#scoring -> accuracy, f1-score 둘 다 해보기\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # 작은 값은 규제를 강하게, 큰 값은 규제를 약하게\n",
        "  }\n",
        "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=5, scoring='f1_macro', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적 모델 확인\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
        "print(f\"훈련 데이터 최적 정확도: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# 🔹 6. 평가 결과 출력\n",
        "print(f\"테스트 데이터 평가 결과:\")\n",
        "print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "print(f\"정밀도 (Precision): {precision:.4f}\")\n",
        "print(f\"재현율 (Recall): {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggv_ZkMIjaIj"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_linear = SVC(kernel='linear',C=10,random_state=42)\n",
        "svm_linear.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HauHUdfHOq39"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "\n",
        "#그리드서치\n",
        "#scoring -> accuracy, f1-score 둘 다 해보기\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # 작은 값은 규제를 강하게, 큰 값은 규제를 약하게\n",
        "    'gamma' : [0.01,0.1,1,10,100]\n",
        "  }\n",
        "grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적 모델 확인\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"최적 하이퍼파라미터:\", grid_search.best_params_)\n",
        "print(f\"훈련 데이터 최적 정확도: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# 🔹 6. 평가 결과 출력\n",
        "print(f\"테스트 데이터 평가 결과:\")\n",
        "print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "print(f\"정밀도 (Precision): {precision:.4f}\")\n",
        "print(f\"재현율 (Recall): {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##베이지안 최적화"
      ],
      "metadata": {
        "id": "ekT4LkZvL4R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# SVM 모델 정의\n",
        "svm = SVC()\n",
        "\n",
        "# 베이지안 최적화를 위한 하이퍼파라미터 범위 설정\n",
        "param_space = {\n",
        "    'C': (0.1, 1000, 'log-uniform'),   # C는 0.1~1000 범위에서 로그 스케일로 탐색\n",
        "    'gamma': (1e-6, 1e+1, 'log-uniform'),  # gamma도 10^(-6) ~ 10^1 범위에서 로그 스케일 탐색\n",
        "    'kernel': ['rbf', 'linear']  # 사용할 커널 목록\n",
        "}\n",
        "\n",
        "# 베이지안 최적화 적용\n",
        "opt = BayesSearchCV(svm, param_space, n_iter=30, cv=3, n_jobs=-1, random_state=42)\n",
        "\n",
        "# 최적화 실행\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best parameters found: \", opt.best_params_)\n",
        "print(\"Best score: \", opt.best_score_)\n",
        "\n",
        "# 최적의 모델 평가\n",
        "best_svm = opt.best_estimator_\n",
        "print(\"Test accuracy: \", best_svm.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "14a2pxIsLeAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best parameters found:  OrderedDict([('C', 177.65766649807682), ('gamma', 1.5962500716886472e-05), ('kernel', 'linear')])\n",
        "\n",
        "\n",
        "Best score:  0.7680764635603344\n",
        "\n",
        "\n",
        "Test accuracy:  0.8316151202749141"
      ],
      "metadata": {
        "id": "YHOuaJDuL8_U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqncYVpefBQm"
      },
      "source": [
        "#랜덤포레스트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aac6w2lIfbgr"
      },
      "source": [
        "##그리드 서치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmFn1wfqfCwq",
        "outputId": "a10b1997-ba32-4c78-eb93-5b9d691f067d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " 최적의 하이퍼파라미터: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 350}\n",
            "최적 OOB Score: 0.6944922547332186\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# 🚀 DataFrame → NumPy 배열 변환 후 ravel() 적용\n",
        "y_train = np.ravel(y_train.values)\n",
        "\n",
        "# 하이퍼파라미터 그리드 설정\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 350, 500],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 10]\n",
        "}\n",
        "\n",
        "best_score = 0\n",
        "best_params = None\n",
        "\n",
        "# 모든 하이퍼파라미터 조합을 탐색\n",
        "for params in ParameterGrid(param_grid):\n",
        "    rf = RandomForestClassifier(oob_score=True, random_state=42, bootstrap=True, **params)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # 최적의 OOB 점수 갱신\n",
        "    if rf.oob_score_ > best_score:\n",
        "        best_score = rf.oob_score_\n",
        "        best_params = params\n",
        "\n",
        "print(\"\\n 최적의 하이퍼파라미터:\", best_params)\n",
        "print(\"최적 OOB Score:\", best_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFo77uE5fUdQ",
        "outputId": "7ca6cf20-22b0-4468-e0a1-dc79cf3c0f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "랜덤포레스트 데이터 정확도 :  0.7061855670103093\n"
          ]
        }
      ],
      "source": [
        "#RF최적 하이퍼파라미터로 테스트\n",
        "from sklearn.metrics import accuracy_score\n",
        "rf = RandomForestClassifier(max_depth = None, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 500, random_state=42)\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"랜덤포레스트 데이터 정확도 : \", accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5CGT6HCfdMm"
      },
      "source": [
        "##베이지안 최적화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgfChGRKf0Dw",
        "outputId": "9df4fe34-aba8-444c-c676-60e07e06ada1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbZ60SFNflhz",
        "outputId": "fe401b3d-f17a-431e-b254-4afdf77d3d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "✅ Best Parameters: OrderedDict([('max_depth', 30), ('max_features', 'sqrt'), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 500)])\n",
            "Best Cross-Validation Score: 0.5550798810813814\n",
            "Best Model's OOB Score: 0.5692771084337349\n",
            "Test Accuracy: 0.5429553264604811\n"
          ]
        }
      ],
      "source": [
        "#베이지안 최적화\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer, Categorical, Real\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 랜덤포레스트 모델\n",
        "rf = RandomForestClassifier(oob_score=True, random_state=42, bootstrap=True)\n",
        "\n",
        "# 베이지안 최적화를 위한 하이퍼파라미터 공간 정의\n",
        "param_space = {\n",
        "    'n_estimators': Integer(50, 500),   # 트리 개수 (50~500)\n",
        "    'max_depth': Integer(3, 30),        # 최대 깊이 (3~30)\n",
        "    'min_samples_split': Integer(2, 20),  # 내부 노드 분할 최소 샘플 수\n",
        "    'min_samples_leaf': Integer(1, 10),  # 리프 노드의 최소 샘플 수\n",
        "    'max_features': Categorical(['sqrt', 'log2'])  # 최대 사용 특성 수\n",
        "}\n",
        "\n",
        "# 베이지안 최적화 설정\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=rf,\n",
        "    search_spaces=param_space,\n",
        "    n_iter=30,  # 30번 최적화 시도\n",
        "    cv=3,  # 3-Fold 교차 검증\n",
        "    n_jobs=-1,  # 병렬 처리\n",
        "    verbose=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"✅ Best Parameters:\", bayes_search.best_params_)\n",
        "\n",
        "# 최적 모델 평가\n",
        "best_rf = bayes_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Best Cross-Validation Score:\", bayes_search.best_score_)\n",
        "print(\"Best Model's OOB Score:\", best_rf.oob_score_)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost"
      ],
      "metadata": {
        "id": "ZFj7DOpELC2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##그리드 서치"
      ],
      "metadata": {
        "id": "60CRmvhxLSgV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EY231kiElby"
      },
      "outputs": [],
      "source": [
        "rom sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "# XGBoost 모델 생성\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
        "\n",
        "# Grid Search 하이퍼파라미터 설정\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'subsample': [0.8, 1],\n",
        "    'colsample_bytree': [0.8, 1],\n",
        "}\n",
        "\n",
        "# Grid Search 실행\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=3,  # 3-Fold Cross Validation\n",
        "    verbose=2,\n",
        "    n_jobs=-1  # 병렬 연산\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 최적의 하이퍼파라미터 확인\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"최적 하이퍼파라미터: {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "최적 하이퍼파라미터: {'colsample_bytree': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1}"
      ],
      "metadata": {
        "id": "eHi72aKqLO2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설정\n",
        "best_model = xgb.XGBClassifier(colsample_bytree = 1,\n",
        "                               learning_rate = 0.2,\n",
        "                               max_depth = 3,\n",
        "                               n_estimators = 200,\n",
        "                               subsample = 1)\n",
        "\n",
        "# 모델 학습\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 정확도 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"모델 정확도: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "ll9pAr2-LMlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##베이지안 최적화"
      ],
      "metadata": {
        "id": "XPyLxTBRLTz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-optimize"
      ],
      "metadata": {
        "id": "TzCHZ07LLUny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# 2️⃣ XGBoost 모델 생성\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "\n",
        "# 3️⃣ 베이지안 최적화를 위한 하이퍼파라미터 범위 설정\n",
        "param_space = {\n",
        "    'max_depth': (3, 10),  # 정수형 범위\n",
        "    'learning_rate': (0.01, 0.3),  # 실수형 범위\n",
        "    'n_estimators': (50, 300),  # 정수형 범위\n",
        "    'subsample': (0.5, 1.0),  # 실수형 범위\n",
        "    'colsample_bytree': (0.5, 1.0)  # 실수형 범위\n",
        "}\n",
        "\n",
        "# 4️⃣ BayesSearchCV 실행\n",
        "opt = BayesSearchCV(\n",
        "    estimator=model,\n",
        "    search_spaces=param_space,\n",
        "    scoring='accuracy',\n",
        "    cv=3,  # 3-Fold Cross Validation\n",
        "    n_iter=20,  # 총 20번의 탐색 (더 늘리면 성능 향상 가능)\n",
        "    random_state=42,\n",
        "    verbose=1,\n",
        "    n_jobs=-1  # 병렬 연산\n",
        ")\n",
        "\n",
        "# 5️⃣ 최적의 하이퍼파라미터 탐색\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "# 6️⃣ 최적 하이퍼파라미터 출력\n",
        "print(\"\\n✅ 최적의 하이퍼파라미터:\", opt.best_params_)\n",
        "print(\"🔥 최적 모델의 정확도:\", opt.best_score_)\n",
        "\n",
        "# 7️⃣ 최적 모델로 테스트 데이터 평가\n",
        "best_model = opt.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(f\"테스트 데이터 정확도: {accuracy_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "SX6K-wdhLaGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최적의 하이퍼파라미터: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.3), ('max_depth', 3), ('n_estimators', 195), ('subsample', 1.0)])\n",
        "\n",
        "\n",
        "최적 모델의 정확도: 0.6725425800894668\n",
        "\n",
        "\n",
        "테스트 데이터 정확도: 0.7165"
      ],
      "metadata": {
        "id": "Fn9UOLtZLccW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}